---
title: 'My Next works'
date: 2024-01-07
permalink: /next/
---

### Interesting papers



1. [Data-Centric Debugging: mitigating model failures via targeted image retrieval](https://openaccess.thecvf.com/content/WACV2024/papers/Singla_Data-Centric_Debugging_Mitigating_Model_Failures_via_Targeted_Image_Retrieval_WACV_2024_paper.pdf)

1. [Bi-directional Training for Composed Image Retrieval via Text Prompt Learning
](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Bi-Directional_Training_for_Composed_Image_Retrieval_via_Text_Prompt_Learning_WACV_2024_paper.pdf)

1. [
DocLLM: A layout-aware generative language model for multimodal document understanding](https://arxiv.org/pdf/2401.00908.pdf)


    1. The paper focuses on the challenges of understanding visually rich documents, such as forms, invoices, receipts, and contracts, which require the integration of textual and spatial modalities.
    1. Existing large language models (LLMs) primarily accept text-only inputs and assume simple layouts, which may not be suitable for handling visual documents.
    1. The proposed DocLLM model is a lightweight extension to traditional LLMs that incorporates ***both textual semantics and spatial layout information***. It avoids expensive image encoders and instead uses bounding box information to capture the spatial layout structure.
    1. The model introduces modifications to the pre-training objective to address irregular layouts and mixed data types in visual documents.
    1. The performance of DocLLM is evaluated on various document intelligence tasks, outperforming state-of-the-art LLMs on most datasets and generalizing well to previously unseen datasets.

<details>
<summary>Notes</summary>
&emsp; 
	
Here is the notes

&emsp; 
</details>